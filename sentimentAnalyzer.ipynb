{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b5d8a2",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Analyzer\n",
    "\n",
    "This notebook implements a tweet sentiment analyzer using NLP techniques. It includes text preprocessing, model training, evaluation, visualization, and an interactive sentiment prediction section.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The project loads tweet datasets, preprocesses the text (lowercasing, URL removal, stopword removal, lemmatization), trains three classifiers (Naive Bayes, SVM, and Logistic Regression) using TF-IDF vectorization, and evaluates the models using metrics and visualizations. Finally, you can analyze new tweets interactively.\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Ensure your dataset CSV files are in a folder named `dataset` (with filenames `Dataset - Train.csv` and `Dataset - Test.csv`).\n",
    "2. Install the required packages listed in `requirements.txt`.\n",
    "3. Run the cells in order to execute the complete pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Download required NLTK resources if not already downloaded\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "    nltk.data.find(\"corpora/stopwords\")\n",
    "    nltk.data.find(\"corpora/wordnet\")\n",
    "except LookupError:\n",
    "    print(\"Downloading required NLTK resources...\")\n",
    "    nltk.download(\"punkt\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    nltk.download(\"wordnet\")\n",
    "\n",
    "# Set display options for better visualization\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d423ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and normalize text data for sentiment analysis.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove mentions and hashtags (replace hashtags with a space)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \" \", text)\n",
    "\n",
    "    # Remove punctuation but keep emoticons like :) :(\n",
    "    text = re.sub(r\"[^\\w\\s:)(;]\", \"\", text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # Tokenize using nltk\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords while preserving key negative words\n",
    "    stop_words = set(stopwords.words(\"english\")) - {\"no\", \"not\", \"nor\", \"neither\", \"never\", \"none\", \"n't\", \"ain't\"}\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Evaluate model performance with metrics and confusion matrix visualization.\"\"\"\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"Negative\", \"Positive\"],\n",
    "        yticklabels=[\"Negative\", \"Positive\"]\n",
    "    )\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create radar chart\n",
    "def create_radar_chart(results_df, metrics):\n",
    "    \"\"\"Create radar chart to compare model performance across metrics.\"\"\"\n",
    "    # Number of variables\n",
    "    categories = metrics\n",
    "    N = len(categories)\n",
    "\n",
    "    # Create angle for each category\n",
    "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "    angles += angles[:1]  # Close the loop\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "    # Draw one axis per variable and add labels\n",
    "    plt.xticks(angles[:-1], categories, size=12)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], [\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], size=10)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    # Plot each model\n",
    "    colors = [\"blue\", \"red\", \"green\", \"purple\"]\n",
    "    for i, row in results_df.iterrows():\n",
    "        values = row[metrics].tolist()\n",
    "        values += values[:1]  # Close the loop\n",
    "\n",
    "        # Plot values\n",
    "        ax.plot(\n",
    "            angles,\n",
    "            values,\n",
    "            linewidth=2,\n",
    "            linestyle=\"solid\",\n",
    "            label=row[\"model\"],\n",
    "            color=colors[i % len(colors)],\n",
    "        )\n",
    "        ax.fill(angles, values, alpha=0.1, color=colors[i % len(colors)])\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend(loc=\"upper right\", bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.title(\"Model Performance Comparison\", size=15)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2381b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create word clouds\n",
    "def plot_word_clouds(df, text_column, sentiment_column, target_entity=None):\n",
    "    \"\"\"Create word clouds showing common words in positive and negative sentiment texts.\"\"\"\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # If target entity is specified, filter data\n",
    "    if target_entity:\n",
    "        entity_col = next(\n",
    "            (\n",
    "                col for col in df.columns \n",
    "                if \"directed\" in col.lower() or \"brand\" in col.lower() or \"entity\" in col.lower() or \"product\" in col.lower()\n",
    "            ),\n",
    "            None\n",
    "        )\n",
    "\n",
    "        if entity_col:\n",
    "            filtered_df = df[df[entity_col].str.contains(target_entity, case=False, na=False)]\n",
    "            if len(filtered_df) < 10:\n",
    "                print(f\"Not enough data for entity '{target_entity}'. Using all data instead.\")\n",
    "                filtered_df = df\n",
    "        else:\n",
    "            filtered_df = df\n",
    "    else:\n",
    "        filtered_df = df\n",
    "\n",
    "    # Get unique sentiment values\n",
    "    sentiment_values = filtered_df[sentiment_column].unique()\n",
    "\n",
    "    # Map sentiment values if needed\n",
    "    if len(sentiment_values) > 2:\n",
    "        print(f\"Multiple sentiment values found: {sentiment_values}\")\n",
    "        print(\"Creating word clouds for the two most common sentiment values.\")\n",
    "        top_sentiments = filtered_df[sentiment_column].value_counts().index[:2]\n",
    "        positive_sentiment = top_sentiments[0]\n",
    "        negative_sentiment = top_sentiments[1] if len(top_sentiments) > 1 else None\n",
    "    else:\n",
    "        if len(sentiment_values) == 2:\n",
    "            if any(pos in str(val).lower() for val in sentiment_values for pos in [\"positive\", \"yes\", \"1\", \"true\"]):\n",
    "                positive_sentiment = next(val for val in sentiment_values if any(pos in str(val).lower() for pos in [\"positive\", \"yes\", \"1\", \"true\"]))\n",
    "                negative_sentiment = next(val for val in sentiment_values if val != positive_sentiment)\n",
    "            else:\n",
    "                positive_sentiment = sentiment_values[0]\n",
    "                negative_sentiment = sentiment_values[1]\n",
    "        elif len(sentiment_values) == 1:\n",
    "            positive_sentiment = sentiment_values[0]\n",
    "            negative_sentiment = None\n",
    "        else:\n",
    "            print(\"No sentiment values found in the dataset.\")\n",
    "            return\n",
    "\n",
    "    # Positive sentiment wordcloud\n",
    "    plt.subplot(1, 2, 1)\n",
    "    positive_mask = filtered_df[sentiment_column] == positive_sentiment\n",
    "    if positive_mask.sum() > 0:\n",
    "        positive_text = \" \".join(filtered_df[positive_mask][text_column])\n",
    "        wordcloud_positive = WordCloud(\n",
    "            width=800,\n",
    "            height=400,\n",
    "            background_color=\"white\",\n",
    "            colormap=\"viridis\",\n",
    "            max_words=100,\n",
    "        ).generate(positive_text)\n",
    "        plt.imshow(wordcloud_positive, interpolation=\"bilinear\")\n",
    "        plt.title(f'Words in {positive_sentiment} Reviews' + (f\" about {target_entity}\" if target_entity else \"\"), fontsize=16)\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, f\"No {positive_sentiment} reviews found\", ha=\"center\", va=\"center\", fontsize=14)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    # Negative sentiment wordcloud\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if negative_sentiment is not None:\n",
    "        negative_mask = filtered_df[sentiment_column] == negative_sentiment\n",
    "        if negative_mask.sum() > 0:\n",
    "            negative_text = \" \".join(filtered_df[negative_mask][text_column])\n",
    "            wordcloud_negative = WordCloud(\n",
    "                width=800,\n",
    "                height=400,\n",
    "                background_color=\"white\",\n",
    "                colormap=\"plasma\",\n",
    "                max_words=100,\n",
    "            ).generate(negative_text)\n",
    "            plt.imshow(wordcloud_negative, interpolation=\"bilinear\")\n",
    "            plt.title(f'Words in {negative_sentiment} Reviews' + (f\" about {target_entity}\" if target_entity else \"\"), fontsize=16)\n",
    "            plt.axis(\"off\")\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, f\"No {negative_sentiment} reviews found\", ha=\"center\", va=\"center\", fontsize=14)\n",
    "            plt.axis(\"off\")\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, \"No second sentiment category found\", ha=\"center\", va=\"center\", fontsize=14)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if target_entity:\n",
    "        plt.savefig(f\"{target_entity.lower()}_sentiment_wordclouds.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.savefig(\"sentiment_wordclouds.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze a new tweet\n",
    "def analyze_tweet(tweet_text, model_pipeline):\n",
    "    \"\"\"Analyze sentiment of a new tweet using the trained model.\"\"\"\n",
    "    # Preprocess the text\n",
    "    processed_text = preprocess_text(tweet_text)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model_pipeline.predict([processed_text])[0]\n",
    "\n",
    "    # Get prediction probability if the model supports predict_proba\n",
    "    try:\n",
    "        probabilities = model_pipeline.predict_proba([processed_text])[0]\n",
    "        confidence = max(probabilities) * 100\n",
    "        return prediction, confidence\n",
    "    except:\n",
    "        return prediction, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to load data, train models, evaluate, and run interactive analysis\n",
    "def main():\n",
    "    try:\n",
    "        # Attempt to load datasets\n",
    "        try:\n",
    "            train_df = pd.read_csv(\"dataset/Dataset - Train.csv\")\n",
    "            test_df = pd.read_csv(\"dataset/Dataset - Test.csv\")\n",
    "            print(\"Datasets loaded successfully!\")\n",
    "            \n",
    "            # Print column names to help debug\n",
    "            print(\"\\nTrain dataset columns:\", train_df.columns.tolist())\n",
    "            print(\"Test dataset columns:\", test_df.columns.tolist())\n",
    "        except FileNotFoundError:\n",
    "            print(\"Dataset files not found. Creating synthetic dataset for demonstration...\")\n",
    "            \n",
    "            from sklearn.datasets import fetch_20newsgroups\n",
    "            \n",
    "            categories = [\"comp.graphics\", \"rec.autos\"]\n",
    "            newsgroups = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42)\n",
    "            \n",
    "            data = pd.DataFrame({\n",
    "                \"tweet_text\": newsgroups.data[:1000],\n",
    "                \"is_there_an_emotion_directed_at_a_brand_or_product\": [\"Positive\" if target == 0 else \"Negative\" for target in newsgroups.target[:1000]],\n",
    "                \"emotion_in_tweet_is_directed_at\": [\n",
    "                    \"Google\" if i % 3 == 0 else \"Microsoft\" if i % 3 == 1 else \"Apple\" for i in range(1000)\n",
    "                ],\n",
    "            })\n",
    "            \n",
    "            train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "            print(\"Synthetic dataset created successfully!\")\n",
    "\n",
    "        # Display dataset information\n",
    "        print(\"\\nTraining dataset info:\")\n",
    "        print(f\"Number of records: {len(train_df)}\")\n",
    "\n",
    "        # Identify text columns in both datasets\n",
    "        train_text_candidates = [col for col in train_df.columns if any(text_indicator in col.lower() for text_indicator in [\"text\", \"tweet\", \"message\", \"content\"])]\n",
    "        \n",
    "        if train_text_candidates:\n",
    "            train_text_col = train_text_candidates[0]\n",
    "        else:\n",
    "            str_cols = [col for col in train_df.columns if train_df[col].dtype == \"object\"]\n",
    "            if str_cols:\n",
    "                avg_lengths = {col: train_df[col].astype(str).str.len().mean() for col in str_cols}\n",
    "                train_text_col = max(avg_lengths.items(), key=lambda x: x[1])[0]\n",
    "            else:\n",
    "                train_text_col = train_df.columns[0]\n",
    "\n",
    "        print(f\"Identified text column in training data: '{train_text_col}'\")\n",
    "\n",
    "        if train_text_col in test_df.columns:\n",
    "            test_text_col = train_text_col\n",
    "        else:\n",
    "            test_text_candidates = [col for col in test_df.columns if any(text_indicator in col.lower() for text_indicator in [\"text\", \"tweet\", \"message\", \"content\"])]\n",
    "            if test_text_candidates:\n",
    "                test_text_col = test_text_candidates[0]\n",
    "            else:\n",
    "                str_cols = [col for col in test_df.columns if test_df[col].dtype == \"object\"]\n",
    "                if str_cols:\n",
    "                    avg_lengths = {col: test_df[col].astype(str).str.len().mean() for col in str_cols}\n",
    "                    test_text_col = max(avg_lengths.items(), key=lambda x: x[1])[0]\n",
    "                else:\n",
    "                    test_text_col = test_df.columns[0]\n",
    "\n",
    "        print(f\"Identified text column in test data: '{test_text_col}'\")\n",
    "\n",
    "        # Identify sentiment column in training dataset\n",
    "        sentiment_candidates = [col for col in train_df.columns if any(sentiment_indicator in col.lower() for sentiment_indicator in [\"emotion\", \"sentiment\", \"feeling\", \"label\", \"class\"])]\n",
    "        \n",
    "        if sentiment_candidates:\n",
    "            sentiment_col = sentiment_candidates[0]\n",
    "        else:\n",
    "            potential_cols = [col for col in train_df.columns if col != train_text_col and train_df[col].nunique() <= 5 and train_df[col].nunique() > 1]\n",
    "            if potential_cols:\n",
    "                sentiment_col = potential_cols[0]\n",
    "            else:\n",
    "                cols = list(train_df.columns)\n",
    "                sentiment_col = cols[1] if len(cols) > 1 and cols[1] != train_text_col else cols[0]\n",
    "\n",
    "        print(f\"Identified sentiment column: '{sentiment_col}'\")\n",
    "\n",
    "        if sentiment_col in test_df.columns:\n",
    "            print(f\"Sentiment column '{sentiment_col}' found in test dataset.\")\n",
    "            test_has_labels = True\n",
    "        else:\n",
    "            print(f\"Sentiment column '{sentiment_col}' not found in test dataset. Creating test set from training data.\")\n",
    "            test_has_labels = False\n",
    "\n",
    "        # Apply preprocessing\n",
    "        print(\"\\nPreprocessing text data...\")\n",
    "        train_df[\"processed_text\"] = train_df[train_text_col].apply(preprocess_text)\n",
    "        test_df[\"processed_text\"] = test_df[test_text_col].apply(preprocess_text)\n",
    "\n",
    "        # Show sample processed texts\n",
    "        print(\"\\nSample processed texts:\")\n",
    "        for i in range(min(3, len(train_df))):\n",
    "            print(f\"Original: {train_df[train_text_col].iloc[i][:100]}...\")\n",
    "            print(f\"Processed: {train_df['processed_text'].iloc[i][:100]}...\")\n",
    "            print(f\"Sentiment: {train_df[sentiment_col].iloc[i]}\")\n",
    "            print()\n",
    "\n",
    "        # Handle sentiment values to ensure they are standardized\n",
    "        sentiment_value_counts = train_df[sentiment_col].value_counts()\n",
    "        print(f\"Sentiment value distribution:\\n{sentiment_value_counts}\")\n",
    "\n",
    "        if train_df[sentiment_col].nunique() > 2 or train_df[sentiment_col].dtype.kind in \"iuf\":\n",
    "            print(\"Converting sentiment values to binary (Positive/Negative)...\")\n",
    "\n",
    "            if train_df[sentiment_col].dtype.kind in \"iuf\":\n",
    "                median = train_df[sentiment_col].median()\n",
    "                train_df[\"sentiment_binary\"] = train_df[sentiment_col].apply(lambda x: \"Positive\" if x >= median else \"Negative\")\n",
    "                if test_has_labels:\n",
    "                    test_df[\"sentiment_binary\"] = test_df[sentiment_col].apply(lambda x: \"Positive\" if x >= median else \"Negative\")\n",
    "            else:\n",
    "                top_sentiment = sentiment_value_counts.index[0]\n",
    "                train_df[\"sentiment_binary\"] = train_df[sentiment_col].apply(lambda x: \"Positive\" if x == top_sentiment else \"Negative\")\n",
    "                if test_has_labels:\n",
    "                    test_df[\"sentiment_binary\"] = test_df[sentiment_col].apply(lambda x: \"Positive\" if x == top_sentiment else \"Negative\")\n",
    "\n",
    "            sentiment_col = \"sentiment_binary\"\n",
    "\n",
    "        # Define X and y for training and testing\n",
    "        X_train = train_df[\"processed_text\"]\n",
    "        y_train = train_df[sentiment_col]\n",
    "        X_test = test_df[\"processed_text\"]\n",
    "\n",
    "        if test_has_labels:\n",
    "            y_test = test_df[sentiment_col]\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "            print(\"Created test set from training data.\")\n",
    "\n",
    "        # Create model pipelines\n",
    "        print(\"\\nCreating model pipelines...\")\n",
    "\n",
    "        nb_pipeline = Pipeline([\n",
    "            (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "            (\"classifier\", MultinomialNB(alpha=1.0))\n",
    "        ])\n",
    "\n",
    "        svm_pipeline = Pipeline([\n",
    "            (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "            (\"classifier\", LinearSVC(C=1.0, max_iter=10000))\n",
    "        ])\n",
    "\n",
    "        lr_pipeline = Pipeline([\n",
    "            (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "            (\"classifier\", LogisticRegression(C=1.0, max_iter=10000))\n",
    "        ])\n",
    "\n",
    "        # Train models\n",
    "        print(\"\\nTraining Naive Bayes model...\")\n",
    "        nb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Training SVM model...\")\n",
    "        svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Training Logistic Regression model...\")\n",
    "        lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred_nb = nb_pipeline.predict(X_test)\n",
    "        y_pred_svm = svm_pipeline.predict(X_test)\n",
    "        y_pred_lr = lr_pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluate models\n",
    "        print(\"\\nEvaluating models on test data:\")\n",
    "        results = []\n",
    "        results.append(evaluate_model(y_test, y_pred_nb, \"Naive Bayes\"))\n",
    "        results.append(evaluate_model(y_test, y_pred_svm, \"SVM\"))\n",
    "        results.append(evaluate_model(y_test, y_pred_lr, \"Logistic Regression\"))\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Bar chart visualization\n",
    "        metrics_list = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "        results_df_melted = pd.melt(results_df, id_vars=[\"model\"], value_vars=metrics_list, var_name=\"metric\", value_name=\"value\")\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=\"metric\", y=\"value\", hue=\"model\", data=results_df_melted)\n",
    "        plt.title(\"Performance Comparison of Sentiment Analysis Models\", fontsize=14)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.legend(title=\"Model\")\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"model_performance_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "        # Radar chart\n",
    "        create_radar_chart(results_df, metrics_list)\n",
    "\n",
    "        # Word cloud visualization\n",
    "        entity_col = next((col for col in train_df.columns if \"brand\" in col.lower() or \"product\" in col.lower() or \"company\" in col.lower() or \"directed\" in col.lower()), None)\n",
    "\n",
    "        if entity_col and entity_col in train_df.columns:\n",
    "            if (not train_df[entity_col].isna().all() and len(train_df[entity_col].dropna()) > 0):\n",
    "                top_entity = train_df[entity_col].value_counts().index[0]\n",
    "                print(f\"\\nCreating word clouds for entity: {top_entity}\")\n",
    "                plot_word_clouds(train_df, \"processed_text\", sentiment_col, top_entity)\n",
    "\n",
    "        print(\"\\nCreating general sentiment word clouds\")\n",
    "        plot_word_clouds(train_df, \"processed_text\", sentiment_col)\n",
    "\n",
    "        # Determine best model based on F1 score\n",
    "        best_model_idx = results_df[\"f1\"].idxmax()\n",
    "        best_model_name = results_df.loc[best_model_idx, \"model\"]\n",
    "\n",
    "        if best_model_name == \"Naive Bayes\":\n",
    "            best_model = nb_pipeline\n",
    "        elif best_model_name == \"SVM\":\n",
    "            best_model = svm_pipeline\n",
    "        else:\n",
    "            best_model = lr_pipeline\n",
    "\n",
    "        print(f\"\\nBest performing model: {best_model_name} with F1 score: {results_df.loc[best_model_idx, 'f1']:.4f}\")\n",
    "\n",
    "        # Interactive tweet analysis\n",
    "        print(\"\\n--- Tweet Sentiment Analyzer ---\")\n",
    "        print(\"Enter tweets to analyze their sentiment (type 'exit' to quit):\")\n",
    "\n",
    "        example_tweets = [\n",
    "            \"I absolutely love my new Google Pixel! The camera is amazing and the battery lasts all day.\",\n",
    "            \"This Apple iPhone keeps crashing and the battery drains too quickly. Terrible experience so far.\",\n",
    "            \"Microsoft's customer service was helpful in resolving my issue with Windows. Good job!\",\n",
    "            \"Netflix recommendations are spot on today. So many good shows to watch!\"\n",
    "        ]\n",
    "\n",
    "        print(\"\\nExample tweets you can try:\")\n",
    "        for i, tweet in enumerate(example_tweets):\n",
    "            print(f\"{i+1}. {tweet}\")\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\"\\nEnter a tweet to analyze (or 'exit' to quit): \")\n",
    "            if user_input.lower() == \"exit\":\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                idx = int(user_input) - 1\n",
    "                if 0 <= idx < len(example_tweets):\n",
    "                    user_input = example_tweets[idx]\n",
    "                    print(f\"Analyzing example tweet: {user_input}\")\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "            sentiment, confidence = analyze_tweet(user_input, best_model)\n",
    "            print(f\"Sentiment: {sentiment}\")\n",
    "            if confidence:\n",
    "                print(f\"Confidence: {confidence:.2f}%\")\n",
    "\n",
    "        print(\"\\nThank you for using the Tweet Sentiment Analyzer!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
